
<!-- saved from url=(0041)http://bisqwit.iki.fi/story/howto/openmp/ -->
<html class="gr__bisqwit_iki_fi"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Guide into OpenMP: Easy multithreading programming for C++</title>
  <link rel="stylesheet" type="text/css" href="./Guide into OpenMP_ Easy multithreading programming for C++_files/css" title="normal">
  <script type="text/javascript" src="./Guide into OpenMP_ Easy multithreading programming for C++_files/mktree.js"></script>
 </head>
 <body data-gr-c-s-loaded="true">


<h1><a name="GuideIntoOpenmpEasyMultithreadingProgrammingForC"></a>Guide into OpenMP: Easy multithreading programming for C++</h1><div class="deeper">
<small>By <a class="extlink" id="i1EE48DDA" href="http://iki.fi/bisqwit/">Joel Yliluoma</a>, September 2007; last update in June 2016 for OpenMP 4.5</small>
<h2><a name="Abstract"></a>Abstract</h2><div class="deeper">
This document attempts to give a quick introduction
to <a class="extlink" id="i43463F8" href="http://www.openmp.org/">OpenMP</a> (as of version 4.5),
a simple C/C++/Fortran compiler extension that allows to add
parallelism into existing source code without significantly
having to rewrite it.
<p>In this document, we concentrate on the C++ language in particular,
and use GCC to compile the examples.
</p><p></p><div class="toc">Table of contents [<span onclick="expandTree(&#39;wikitoc1&#39;)" class="mktreecmd">expand all</span>] [<span onclick="collapseTree(&#39;wikitoc1&#39;)" class="mktreecmd">collapse all</span>]<br>
<ul class="mktree" id="wikitoc1"><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Abstract">Abstract
</a></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#PrefaceImportanceOfMultithreading">Preface: Importance of multithreading
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#SupportInDifferentCompilers">Support in different compilers
</a></li></ul></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#IntroductionToOpenmpInC">Introduction to OpenMP in C++
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ExampleInitializingATableInParallelMultipleThreads">Example: Initializing a table in parallel (multiple threads)
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ExampleInitializingATableInParallelSingleThreadSimd">Example: Initializing a table in parallel (single thread, SIMD)
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ExampleInitializingATableInParallelMultipleThreadsOnAnotherDevice">Example: Initializing a table in parallel (multiple threads on another device)
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ExampleCalculatingTheMandelbrotFractalInParallelHostComputer">Example: Calculating the Mandelbrot fractal in parallel (host computer)
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Discussion">Discussion
</a></li></ul></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Syntax">The syntax
</a><ul><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ParallelConstruct">The <tt>parallel</tt> construct
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ParallelismConditionalityClauseIf">Parallelism conditionality clause: <tt>if</tt>
</a></li></ul></li><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#LoopConstructFor">Loop construct: <tt>for</tt>
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#WhatAreParallelForAndATeam">What are: <tt>parallel</tt>, <tt>for</tt> and a team
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Scheduling">Scheduling
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#OrderedClause">The <tt>ordered</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#CollapseClause">The <tt>collapse</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ReductionClause">The <tt>reduction</tt> clause
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Sections">Sections
</a></li><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#SimdConstructOpenmp 4 0">The <tt>simd</tt> construct (OpenMP 4.0+)
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#TheCollapseClause">The <tt>collapse</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#TheReductionClause">The <tt>reduction</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#AlignedClause">The <tt>aligned</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#SafelenClause">The <tt>safelen</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#SimdlenClauseOpenmp 4 5">The <tt>simdlen</tt> clause (OpenMP 4.5+)
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#UniformClause">The <tt>uniform</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#LinearClauseOpenmp 4 5">The <tt>linear</tt> clause (OpenMP 4.5+)
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#InbranchAndNotinbranchClauses">The <tt>inbranch</tt> and <tt>notinbranch</tt> clauses
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ForSimdConstructOpenmp 4 0">The <tt>for simd</tt> construct (OpenMP 4.0+)
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#TaskConstructOpenmp 3 0">The <tt>task</tt> construct (OpenMP 3.0+)
</a></li></ul></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#OffloadingSupport">Offloading support
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DeclareTargetAndEndDeclareTargetDirectives">The <tt>declare target</tt> and <tt>end declare target</tt> directives
</a></li><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#TargetTargetDataConstructs">The <tt>target</tt>, <tt>target data</tt> constructs
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#IfClause">The <tt>if</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DeviceClause">The <tt>device</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#MapClause">The <tt>map</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ArraySectionsOpenmp 4 0">Array sections (OpenMP 4.0+)
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#TargetEnterDataAndTargetExitDataConstructsOpenmp 4 5">The <tt>target enter data</tt> and <tt>target exit data</tt> constructs (OpenMP 4.5+)
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#TargetUpdateConstruct">The <tt>target update</tt> construct
</a></li></ul></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Teams">Teams
</a><ul><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DistributeConstruct">The <tt>distribute</tt> construct
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DistributeSimdConstruct">The <tt>distribute simd</tt> construct
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DistScheduleClause">The <tt>dist_schedule</tt> clause
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DistributeParallelForConstruct">The <tt>distribute parallel for</tt> construct
</a></li></ul></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ThreadSafetyIEMutualExclusion">Thread-safety (i.e. mutual exclusion)
</a><ul><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Atomicity">Atomicity
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#AtomicReadExpressions">Atomic read expressions
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#AtomicWriteExpressions">Atomic write expressions
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#AtomicUpdateExpressions">Atomic update expressions
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#AtomicCaptureExpressions">Atomic capture expressions
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#CriticalConstruct">The <tt>critical</tt> construct
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Locks">Locks
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#FlushDirective">The <tt>flush</tt> directive
</a></li></ul></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ControllingWhichDataToShareBetweenThreads">Controlling which data to share between threads
</a><ul><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#PrivateFirstprivateAndSharedClauses">The <tt>private</tt>, <tt>firstprivate</tt> and <tt>shared</tt> clauses
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DifferenceBetweenPrivateAndFirstprivate">The difference between <tt>private</tt> and <tt>firstprivate</tt>
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#LastprivateClause">The <tt>lastprivate</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DefaultClause">The <tt>default</tt> clause
</a></li><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#TheReductionClause_2">The <tt>reduction</tt> clause
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#DeclareReductionDirectiveOpenmp 4 0">The <tt>declare reduction</tt> directive (OpenMP 4.0+)
</a></li></ul></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ThreadAffinityProcBind">Thread affinity (<tt>proc_bind</tt>)
</a></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ExecutionSynchronization">Execution synchronization
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#BarrierDirectiveAndTheNowaitClause">The <tt>barrier</tt> directive and the <tt>nowait</tt> clause
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#SingleAndMasterConstructs">The <tt>single</tt> and <tt>master</tt> constructs
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#ThreadCancellationOpenmp 4 0">Thread cancellation (OpenMP 4.0+)
</a></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#LoopNesting">Loop nesting
</a><ul><li class="liClosed"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Problem">The problem
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#SolutionInOpenmp 3 0">Solution in OpenMP 3.0
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Restrictions">Restrictions
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Performance">Performance
</a></li><li class="liOpen"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#Shortcomings">Shortcomings
</a><ul><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#OpenmpAndFork">OpenMP and fork()
</a></li></ul></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#MissingInThisArticle">Missing in this article
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#SomeSpecificGotchas">Some specific gotchas
</a></li><li class="liBullet"><span class="bullet">&nbsp;</span><a href="http://bisqwit.iki.fi/story/howto/openmp/#FurtherReading">Further reading
</a></li></ul></div>
</div><h2><a name="PrefaceImportanceOfMultithreading"></a>Preface: Importance of multithreading</h2><div class="deeper">
As CPU speeds no longer improve as significantly as they did before,
multicore systems are becoming more popular.
<p>To harness that power, it is becoming important for programmers to
be knowledgeable in parallel programming — making a program execute
multiple things simultaneously.
</p><p>This document attempts to give a quick introduction to <a class="extlink" id="i43463F8" href="http://www.openmp.org/">OpenMP</a>,
a simple C/C++/Fortran compiler extension that allows to add
parallelism into existing source code without significantly
having to entirely rewrite it.
</p><h3><a name="SupportInDifferentCompilers"></a>Support in different compilers</h3><div class="deeper">
<ul><li> <b>GCC</b> (GNU Compiler Collection) supports OpenMP <b>4.5</b> since version 6.1, OpenMP 4.0 since version 4.9, OpenMP 3.1 since version 4.7, OpenMP 3.0 since version 4.4, and OpenMP 2.5 since version 4.2. Add the commandline option <tt>-fopenmp</tt> to enable it. OpenMP <em>offloading</em> is supported for Intel MIC targets only (Intel Xeon Phi KNL + emulation) since version 5.1.
</li><li> <b>Clang++</b> supports OpenMP <b>3.1</b> since version 3.7, and some elements of OpenMP 4.0 since version 3.8. Add the commandline option <tt>-fopenmp</tt> to enable it.
</li><li> <b>Solaris Studio</b> supports OpenMP <b>4.0</b> since version 12.4, and OpenMP 3.1 since version 12.3. Add the commandline option <tt>-xopenmp</tt> to enable it.
</li><li> <b>Intel C Compiler</b> (icc) supports OpenMP <b>4.0</b> since version 15.0, OpenMP 3.1 since version 12.1, OpenMP 3.0 since version 11.0, and OpenMP 2.5 since version 10.1. Add the commandline option <tt>-openmp</tt> to enable it. Add the <tt>-openmp-stubs</tt> option instead to enable the library without actual parallel execution.
</li><li> <b>Microsoft Visual C++</b> (cl) supports OpenMP <b>2.0</b> since version 2005.  Add the commandline option <tt>/openmp</tt> to enable it.
</li></ul><p>Note: If your GCC complains that "-fopenmp" is valid for D but not for C++
when you try to use it, or does not recognize the option at all, your GCC
version is too old. If your linker complains about missing GOMP functions,
you forgot to specify "-fopenmp" in the linking.
</p><p>More information: <a class="extlink" id="iA546AB2C" href="http://openmp.org/wp/openmp-compilers/">http://openmp.org/wp/openmp-compilers/</a>
</p></div></div><h2><a name="IntroductionToOpenmpInC"></a>Introduction to OpenMP in C++</h2><div class="deeper">
OpenMP consists of a set of compiler <tt>#pragma</tt>s that control how
the program works. The pragmas are designed so that even if the compiler
does not support them, the program will still yield correct behavior,
but without any parallelism.
<p>Here are two simple example programs demonstrating OpenMP.
</p><p>You can compile them like this:
</p><pre>  g++ tmp.cpp -fopenmp
</pre><h3><a name="ExampleInitializingATableInParallelMultipleThreads"></a>Example: Initializing a table in parallel (multiple threads)</h3><div class="deeper">
This code divides the table initialization into
multiple threads, which are run simultaneously.
Each thread initializes a portion of the table.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;cmath&gt;
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> size </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">256</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">double</span><span class="jSf6Z2BR2"> sinTable</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2">    
    </span><span class="jSf-8GPi2">#pragma omp parallel for
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">      sinTable</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">sin</span><span class="jSfoF-_93">(</span><span class="jSfJnSXl1">2</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> M_PI </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> n </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> size</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  
    </span><span class="jSfnT6pa2">// the table is now initialized
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
</div><h3><a name="ExampleInitializingATableInParallelSingleThreadSimd"></a>Example: Initializing a table in parallel (single thread, SIMD)</h3><div class="deeper">
This version requires compiler support for at least OpenMP 4.0,
and the use of a parallel floating point library such as AMD ACML
or Intel SVML (which can be used in GCC with e.g. ‑mveclibabi=svml).
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;cmath&gt;
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> size </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">256</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">double</span><span class="jSf6Z2BR2"> sinTable</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2">    
    </span><span class="jSf-8GPi2">#pragma omp simd
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">      sinTable</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">sin</span><span class="jSfoF-_93">(</span><span class="jSfJnSXl1">2</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> M_PI </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> n </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> size</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  
    </span><span class="jSfnT6pa2">// the table is now initialized
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
</div><h3><a name="ExampleInitializingATableInParallelMultipleThreadsOnAnotherDevice"></a>Example: Initializing a table in parallel (multiple threads on another device)</h3><div class="deeper">
OpenMP 4.0 added support for offloading code to different devices, such as a GPU.
Therefore there can be three layers of parallelism in a single program: Single
thread processing multiple data; multiple threads running simultaneously;
and multiple devices running same program simultaneously.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;cmath&gt;
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> size </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">256</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">double</span><span class="jSf6Z2BR2"> sinTable</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2">    
    </span><span class="jSf-8GPi2">#pragma omp target teams distribute parallel for map(from:sinTable[0:256])
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">      sinTable</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">sin</span><span class="jSfoF-_93">(</span><span class="jSfJnSXl1">2</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> M_PI </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> n </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> size</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">    </span><span class="jSfnT6pa2">// the table is now initialized
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
</div><h3><a name="ExampleCalculatingTheMandelbrotFractalInParallelHostComputer"></a>Example: Calculating the Mandelbrot fractal in parallel (host computer)</h3><div class="deeper">
This program calculates the classic
<a class="extlink" id="i16BA8AAA" href="http://en.wikipedia.org/wiki/Mandelbrot_fractal">Mandelbrot fractal</a>
at a low resolution and renders it with ASCII characters,
calculating multiple pixels in parallel.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;complex&gt;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;cstdio&gt;
</span><span class="jSf6Z2BR2"> 
 </span><span class="jSf5gZog2">typedef</span><span class="jSf6Z2BR2"> std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">complex</span><span class="jSfoF-_93">&lt;</span><span class="jSf5gZog2">double</span><span class="jSfoF-_93">&gt;</span><span class="jSf6Z2BR2"> complex</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> 
 </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> MandelbrotCalculate</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">complex c</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> maxiter</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     </span><span class="jSfnT6pa2">// iterates z = z + c until |z| &gt;= 2 or maxiter is reached,
</span><span class="jSf6Z2BR2">     </span><span class="jSfnT6pa2">// returns the number of iterations.
</span><span class="jSf6Z2BR2">     complex z </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> c</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">maxiter</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">         </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2"> std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">abs</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">z</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">&gt;=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">2.0</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">break</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         z </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> z</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">z </span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2"> c</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> n</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> width </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">78</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> height </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">44</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> num_pixels </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> width</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">height</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     
     </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> complex center</span><span class="jSfoF-_93">(-</span><span class="jSfJnSXl1">.7</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> span</span><span class="jSfoF-_93">(</span><span class="jSfJnSXl1">2.7</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">-(</span><span class="jSfJnSXl1">4</span><span class="jSfoF-_93">/</span><span class="jSfJnSXl1">3.0</span><span class="jSfoF-_93">)*</span><span class="jSfJnSXl1">2.7</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">height</span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2">width</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> complex begin </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> center</span><span class="jSfoF-_93">-</span><span class="jSf6Z2BR2">span</span><span class="jSfoF-_93">/</span><span class="jSfJnSXl1">2.0</span><span class="jSf9DH-K2">;</span><span class="jSfnT6pa2">//, end = center+span/2.0;
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> maxiter </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">100000</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   
   </span><span class="jSf-8GPi2">#pragma omp parallel for ordered schedule(dynamic)
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> pix</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> pix</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">num_pixels</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">pix</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">         </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> pix</span><span class="jSfoF-_93">%</span><span class="jSf6Z2BR2">width</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> y </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> pix</span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2">width</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         
         complex c </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> begin </span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2"> complex</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">x </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> span</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">real</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">width </span><span class="jSfoF-_93">+</span><span class="jSfJnSXl1">1.0</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">,
</span><span class="jSf6Z2BR2">                                     y </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> span</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">imag</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">height</span><span class="jSfoF-_93">+</span><span class="jSfJnSXl1">1.0</span><span class="jSfoF-_93">))</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         
         </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> MandelbrotCalculate</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">c</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> maxiter</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">n </span><span class="jSfoF-_93">==</span><span class="jSf6Z2BR2"> maxiter</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> n </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         
       </span><span class="jSf-8GPi2">#pragma omp ordered
</span><span class="jSf6Z2BR2">         </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">           </span><span class="jSf5gZog2">char</span><span class="jSf6Z2BR2"> c </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfS2T7e3">'</span><span class="jSfOFhya3"> </span><span class="jSfS2T7e3">'</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">           </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">n </span><span class="jSfoF-_93">&gt;</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">           </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">               </span><span class="jSf5gZog2">static</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSf6Z2BR2"> charset</span><span class="jSf9DH-K2">[]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">.,c8M@jawrpogOQEPGJ</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">               c </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> charset</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n </span><span class="jSfoF-_93">%</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSfWtbTI">sizeof</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">charset</span><span class="jSfoF-_93">)-</span><span class="jSfJnSXl1">1</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2">           </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">           std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">putchar</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">c</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">           </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">x</span><span class="jSfoF-_93">+</span><span class="jSfJnSXl1">1</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">==</span><span class="jSf6Z2BR2"> width</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">puts</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">|</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
This program can be improved in many different ways,
but it is left simple for the sake of an introductory example.
</div><h3><a name="Discussion"></a>Discussion</h3><div class="deeper">
As you can see, there is very little in the program that indicates that it runs
in parallel. If you remove the <tt>#pragma</tt> lines, the result is still a valid
C++ program that runs and does the expected thing.
<p>Only when the compiler interprets those <tt>#pragma</tt> lines, it becomes a parallel
program. It really does calculate N values simultaneously where N is the number
of threads. In GCC, libgomp determines that from the number of processors.
</p><p>By C and C++ standards, if the compiler encounters a <tt>#pragma</tt> that it does
not support, it will ignore it. So adding the OMP statements can be done safely<a name="r1"></a><sup>[<a href="http://bisqwit.iki.fi/story/howto/openmp/#1">1</a>]</sup>
without breaking compatibility with legacy compilers.
</p><p>There is also a runtime library that can be accessed through <tt>omp.h</tt>,
but it is less often needed. If you need it, you can check
the #define <tt>_OPENMP</tt> for conditional compilation
in case of compilers that don't support OpenMP.
</p><p>[<a name="1"></a><a href="http://bisqwit.iki.fi/story/howto/openmp/#r1">1</a>]: Within the usual parallel programming issues (concurrency, mutual exclusion) of course.
</p></div></div><h2><a name="Syntax"></a>The syntax</h2><div class="deeper">
All OpenMP constructs in C and C++ are indicated with a <tt>#pragma omp</tt> followed
by parameters, ending in a newline.
The pragma usually applies only into the statement immediately following it,
except for the <tt>barrier</tt> and <tt>flush</tt> commands, which do not have associated
statements.
<h3><a name="ParallelConstruct"></a>The <tt>parallel</tt> construct</h3><div class="deeper">
The parallel construct starts a parallel block.
It creates a <em>team</em> of N threads
(where N is determined at runtime, usually from the number
of CPU cores, but may be affected by a few things),
all of which execute the next statement (or the next block, if the statement
is a {…} -enclosure). After the statement, the threads join back into one.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSfnT6pa2">// Code inside this region runs in parallel.
</span><span class="jSf6Z2BR2">    printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">Hello!\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
This code creates a team of threads, and each thread executes the same code.
It prints the text "Hello!" followed by a newline,
as many times as there are threads in the team created.
For a dual-core system, it will output the text twice.
(Note: It may also output something like "HeHlellolo", depending
on system, because the printing happens in parallel.)
At the <tt><em></em>}<em></em></tt>, the threads are joined back into one, as if in non-threaded program.
<p>Internally, GCC implements this by creating a magic function and
moving the associated code into that function, so that all the
variables declared within that block become local variables of
that function (and thus, locals to each thread).<br>
ICC, on the other hand, uses a mechanism resembling <tt>fork()</tt>,
and does not create a magic function. Both implementations are,
of course, valid, and semantically identical.
</p><p>Variables shared from the context are handled transparently,
sometimes by passing a reference and sometimes by using register
variables which are flushed at the end of the parallel block
(or whenever a <tt>flush</tt> is executed).
</p><h4><a name="ParallelismConditionalityClauseIf"></a>Parallelism conditionality clause: <tt>if</tt></h4><div class="deeper">
The parallelism can be made <em>conditional</em> by
including a <tt>if</tt> clause in the parallel command, such as:
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">extern</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> parallelism_enabled</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp parallel for if(parallelism_enabled)
</span><span class="jSf6Z2BR2">  </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> c</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> c</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">c</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">    handle</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">c</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>In this case, if <tt>parallelism_enabled</tt> evaluates
to a zero value, the number of threads in the team
that processes the <tt>for</tt> loop will always be exactly one.
</div></div><h3><a name="LoopConstructFor"></a>Loop construct: <tt>for</tt></h3><div class="deeper">
The <tt>for</tt> construct splits the for-loop so that each thread in
the current team handles a different portion of the loop.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp for
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">.\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>
This loop will output each number from 0…9 once.
However, it may do it in arbitrary order. It may output, for example:
<pre>  0 5 6 7 1 8 2 3 4 9.
</pre>Internally, the above loop becomes into code equivalent to this:
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> this_thread </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> omp_get_thread_num</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> num_threads </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> omp_get_num_threads</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> my_start </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">this_thread  </span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">10</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> num_threads</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> my_end   </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">this_thread</span><span class="jSfoF-_93">+</span><span class="jSfJnSXl1">1</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">10</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> num_threads</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2">my_start</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">my_end</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">    printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>
So each thread gets a different section of the loop, and they
execute their own sections in parallel.
<p>Note: <tt>#pragma omp for</tt> only delegates portions of the loop
for different threads in the <em>current team</em>. A <em>team</em> is the
group of threads executing the program. At program start, the team
consists only of a single member: the master thread that runs
the program.
</p><p>To create a new team of threads, you need to specify the <tt>parallel</tt>
keyword. It can be specified in the surrounding context:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp for
</span><span class="jSf6Z2BR2">  </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">.\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>Equivalent shorthand is to specify it in the pragma
itself, as <tt>#pragma omp parallel for</tt>:
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel for
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">.\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>
You can explicitly specify the number of threads to be created
in the team, using the <tt>num_threads</tt> attribute:
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel num_threads(3)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSfnT6pa2">// This code will be executed by three threads.
</span><span class="jSf6Z2BR2">   
   </span><span class="jSfnT6pa2">// Chunks of this loop will be divided amongst
</span><span class="jSf6Z2BR2">   </span><span class="jSfnT6pa2">// the (three) threads of the current team.
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp for
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
Note that OpenMP also works for C. However, in C, you
need to set explicitly the loop variable as <tt>private</tt>,
because C does not allow declaring it in the loop body:
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp for private(n)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">.\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>See the "private and shared clauses" section for details.
<p>In OpenMP 2.5, the iteration variable in <tt>for</tt> must be a signed
integer variable type. In OpenMP 3.0, it may also be an unsigned
integer variable type, a pointer type or a constant-time random
access iterator type. In the latter case, <tt>std::distance()</tt> will
be used to determine the number of loop iterations.
</p><h4><a name="WhatAreParallelForAndATeam"></a>What are: <tt>parallel</tt>, <tt>for</tt> and a team</h4><div class="deeper">
The difference between <tt>parallel</tt>, <tt>parallel for</tt> and <tt>for</tt> is as follows:
<ul><li> A team is the group of threads that execute currently.
<ul><li> At the program beginning, the team consists of a single thread.
</li><li> A <tt>parallel</tt> construct splits the current thread into <em>a new team</em> of threads for the duration of the next block/statement, after which the team merges back into one.
</li></ul></li><li> <tt>for</tt> divides the work of the for-loop among the threads of the <em>current team</em>. It does not create threads, it only divides the work amongst the threads of the currently executing team.
</li><li> <tt>parallel for</tt> is a shorthand for two commands at once: <tt>parallel</tt> and <tt>for</tt>. Parallel creates a new team, and <tt>for</tt> splits that team to handle different portions of the loop.
</li></ul><p>If your program never contains a <tt>parallel</tt> construct, there
is never more than one thread; the master thread that starts
the program and runs it, as in non-threading programs.
</p></div><h4><a name="Scheduling"></a>Scheduling</h4><div class="deeper">
The scheduling algorithm for the for-loop can explicitly controlled.
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp for schedule(static)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">.\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>
There are five scheduling types: <tt>static</tt>, <tt>dynamic</tt>, <tt>guided</tt>,
<tt>auto</tt>, and (since OpenMP 4.0) <tt>runtime</tt>.
In addition, there are three scheduling modifiers
(since OpenMP 4.5): <tt>monotonic</tt>, <tt>nonmonotonic</tt>, and <tt>simd</tt>.
<p><tt>static</tt> is the default schedule as shown above. Upon entering
the loop, each thread independently decides which chunk of the loop
they will process.
</p><p>There is also the <tt>dynamic</tt> schedule:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp for schedule(dynamic)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">.\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>
In the dynamic schedule, there is no predictable order in which
the loop items are assigned to different threads. Each thread
asks the OpenMP runtime library for an iteration number, then
handles it, then asks for next, and so on.
This is most useful when used in conjunction with the <tt>ordered</tt>
clause, or when the different iterations in the loop may take
different time to execute.
<p>The chunk size can also be specified to lessen the number
of calls to the runtime library:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp for schedule(dynamic, 3)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">.\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>In this example, each thread asks for an iteration number,
executes 3 iterations of the loop, then asks for another,
and so on. The last chunk may be smaller than 3, though.
<p>Internally, the loop above becomes into code equivalent to
this (illustration only, do not write code like this):
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">b</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">GOMP_loop_dynamic_start</span><span class="jSfoF-_93">(</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">,</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">,</span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">3</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2">a</span><span class="jSf9DH-K2">,</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2">b</span><span class="jSfoF-_93">))
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">do</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">      </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2">a</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">b</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2"> %d</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">while</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">GOMP_loop_dynamic_next</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">a</span><span class="jSf9DH-K2">,</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2">b</span><span class="jSfoF-_93">))</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
The <tt>guided</tt> schedule appears to have behavior of <tt>static</tt>
with the shortcomings of <tt>static</tt> fixed with <tt>dynamic</tt>-like traits.
It is difficult to explain —
<a class="extlink" id="i127A9E53" href="http://bisqwit.iki.fi/jutut/kuvat/openmphowto/mandelbrot-demo.zip">this example program</a>
maybe explains it better than words do. (Requires libSDL to compile.)
<p>The "runtime" option means the runtime library chooses one of the
scheduling options at runtime at the compiler library's discretion.
</p><p>A scheduling modifier can be added to the clause, e.g.: <tt>#pragma omp for schedule(nonmonotonic:dynamic</tt><br>
The modifiers are:
</p><ul><li> <tt>monotonic</tt>: Each thread executes chunks in an increasing iteration order.
</li><li> <tt>nonmonotonic</tt>: Each thread executes chunks in an unspecified order.
</li><li> <tt>simd</tt>: If the loop is a <tt>simd</tt> loop, this controls the chunk size for scheduling in a manner that is optimal for the hardware limitations according to how the compiler decides. This modifier is ignored for non-SIMD loops.
</li></ul></div><h4><a name="OrderedClause"></a>The <tt>ordered</tt> clause</h4><div class="deeper">
The order in which the loop iterations are executed is unspecified,
and depends on runtime conditions.
<p>However, it is possible to force that certain events within the loop happen
in a predicted order, using the <tt>ordered</tt> clause.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp for ordered schedule(dynamic)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">100</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   files</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">compress</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp ordered
</span><span class="jSf6Z2BR2">   send</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">files</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>This loop "compresses" 100 files with some files being compressed
in parallel, but ensures that the files are "sent" in a strictly sequential order.
<p>If the thread assigned to compress file 7 is done but the file 6 has
not yet been sent, the thread will wait before sending, and before
starting to compress another file. The <tt>ordered</tt> clause in the
loop guarantees that there always exists one thread that is
handling the lowest-numbered unhandled task.
</p><p>Each file is compressed and sent exactly once, but the
compression may happen in parallel.
</p><p>There may only be one <tt>ordered</tt> block per an ordered
loop, no less and no more. In addition, the enclosing
<tt>for</tt> construct must contain the <tt>ordered</tt> clause.
</p><p>OpenMP 4.5 added some modifiers and clauses to the <tt>ordered</tt> construct.
</p><p></p><ul><li> <tt>#pragma omp ordered threads</tt> means the same as <tt>#pragma omp ordered</tt>. It means the threads executing the loop execute the <tt>ordered</tt> regions sequentially in the order of loop iterations.
</li><li> <tt>#pragma omp ordered simd</tt> can only be used in a <tt>for simd</tt> loop.
</li><li> <tt>#pragma omp ordered depend(source)</tt> and <tt>#pragma omp ordered depend(</tt>vectorvariable<tt>)</tt> also exist.
</li></ul></div><h4><a name="CollapseClause"></a>The <tt>collapse</tt> clause</h4><div class="deeper">
When you have nested loops, you can use the <tt>collapse</tt> clause
to apply the threading to multiple nested iterations.
<p>Example:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel for collapse(2)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> y</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> y</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">25</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">y</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> x</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">80</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">x</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     tick</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">y</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}</span></pre>
</div><h4><a name="ReductionClause"></a>The <tt>reduction</tt> clause</h4><div class="deeper">
The <tt>reduction</tt> clause is a special directive that instructs
the compiler to generate code that accumulates values from different
loop iterations together in a certain manner. It is discussed in a
separate chapter later in this article. Example:
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> sum</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel for reduction(+:sum)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">1000</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> sum </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> table</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">];</span></pre>
</div></div><h3><a name="Sections"></a>Sections</h3><div class="deeper">
Sometimes it is handy to indicate that "this and this can run in parallel".
The <tt>sections</tt> setting is just for that.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp sections
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work1</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp section
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work2</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     Work3</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp section
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work4</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
This code indicates that any of the tasks <tt>Work1</tt>, <tt>Work2 + Work3</tt> and <tt>Work4</tt>
may run in parallel, but that <tt>Work2</tt> and <tt>Work3</tt> must be run in sequence.
Each work is done exactly once.
<p>As usual, if the compiler ignores the pragmas, the result is still a correctly
running program.
</p><p>Internally, GCC implements this as a combination of the parallel <tt>for</tt>
and a switch-case construct. Other compilers may implement it differently.
</p><p>Note: <tt>#pragma omp sections</tt> only delegates the sections
for different threads in the current team. To create a team, you
need to specify the <tt>parallel</tt> keyword either in the surrounding
context or in the pragma, as <tt>#pragma omp parallel sections</tt>.<br>
Example:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel sections </span><span class="jSfQHvUD">// starts a new team
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work1</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp section
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work2</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     Work3</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp section
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work4</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
or
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel </span><span class="jSfQHvUD">// starts a new team
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSfnT6pa2">//Work0(); // this function would be run by all threads.
</span><span class="jSf6Z2BR2">   
   </span><span class="jSf-8GPi2">#pragma omp sections </span><span class="jSfQHvUD">// divides the team into sections
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> 
     </span><span class="jSfnT6pa2">// everything herein is run only once.
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work1</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">     </span><span class="jSf-8GPi2">#pragma omp section
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work2</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">       Work3</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">     </span><span class="jSf-8GPi2">#pragma omp section
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Work4</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   
   </span><span class="jSfnT6pa2">//Work5(); // this function would be run by all threads.
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
</div><h3><a name="SimdConstructOpenmp 4 0"></a>The <tt>simd</tt> construct (OpenMP 4.0+)</h3><div class="deeper">
OpenMP 4.0 added explicit SIMD parallelism (Single-Instruction, Multiple-Data).
SIMD means that multiple calculations will be performed simultaneously by the processor,
using special instructions that perform the same calculation to multiple values at once.
This is often more efficient than regular instructions that operate on single data values.
This is also sometimes called <em>vector parallelism</em> or vector operations
(and is in fact the preferred term in <em>OpenACC</em>).
<p>There are two use cases for the <tt>simd</tt> construct.
</p><p>Firstly, <tt>#pragma omp simd</tt> can be used to declare that a loop will be utilizing SIMD.
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">float</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">],</span><span class="jSf6Z2BR2"> b</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">...
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp simd
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> b</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">];</span></pre>
Secondly, <tt>#pragma omp declare simd</tt> can be used to indicate a function or procedure
that is explicitly designed to take advantage of SIMD parallelism.
The compiler may create multiple versions of the same function that use different
parameter passing conventions for different CPU capabilities for SIMD processing.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp declare simd aligned(a,b:16)
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> add_arrays</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">float</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">__restrict__ a</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">float</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">__restrict__ b</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp simd aligned(a,b:16)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> b</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}	</span></pre>
Without the pragma, the function will use the default non-SIMD-aware ABI,
even though the function itself may do calculation using SIMD.
<h4><a name="TheCollapseClause"></a>The <tt>collapse</tt> clause</h4><div class="deeper">
The <tt>collapse</tt> clause can be added to bind the SIMDness
into multiple nested loops. The example code below will direct
the compiler into attempting to generate instructions that
calculate 16 values simultaneously, if at all possible.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp simd collapse(2)
</span><span class="jSf6Z2BR2">  </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> i</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> i</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">4</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">i</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> j</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> j</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">4</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">j</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">      a</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">j</span><span class="jSfoF-_93">*</span><span class="jSfJnSXl1">4</span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2">i</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> b</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">i</span><span class="jSfoF-_93">*</span><span class="jSfJnSXl1">4</span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2">j</span><span class="jSf9DH-K2">];</span></pre>
</div><h4><a name="TheReductionClause"></a>The <tt>reduction</tt> clause</h4><div class="deeper">
The <tt>reduction</tt> clause can be used with SIMD just like with parallel loops.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> sum</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp simd reduction(+:sum)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">1000</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> sum </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> table</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">];</span></pre>
</div><h4><a name="AlignedClause"></a>The <tt>aligned</tt> clause</h4><div class="deeper">
The <tt>aligned</tt> attribute hints the compiler that each
element listed is aligned to the given number of bytes.
Use this attribute if you are sure that the alignment is guaranteed,
and it will increase the performance of the code and make it shorter.
<p>The attribute can be used in both the function declaration,
and in the individual SIMD statements.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp declare simd aligned(a,b:16)
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> add_arrays</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">float</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">__restrict__ a</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">float</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">__restrict__ b</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp simd aligned(a,b:16)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> b</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}	</span></pre>
</div><h4><a name="SafelenClause"></a>The <tt>safelen</tt> clause</h4><div class="deeper">
While the <tt>restrict</tt> keyword in C tells the compiler
that it can assume that two pointers will not address the same data
(and thus it is safe to change the ordering of reads and writes),
the <tt>safelen</tt> clause in OpenMP provides much fine-grained
control over pointer aliasing.
<p>In the example code below, the compiler is informed that
<tt>a[x]</tt> and <tt>b[y]</tt> are independent <em>as long as</em> the
difference between x and y is smaller than 4.
In reality, the clause controls the upper limit of concurrent
loop iterations. It means that only 4 items can be processed
concurrently at most. The actual concurrency may be smaller,
and depends on the compiler implementation and hardware limits.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp declare simd
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> add_arrays</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">float</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">float</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> b</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp simd aligned(a,b:16) safelen(4)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> b</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}	</span></pre>
</div><h4><a name="SimdlenClauseOpenmp 4 5"></a>The <tt>simdlen</tt> clause (OpenMP 4.5+)</h4><div class="deeper">
The <tt>simdlen</tt> clause can be added to a <tt>declare simd</tt> construct
to limit how many elements of an array are passed in SIMD registers
instead of using the normal parameter passing convention.
</div><h4><a name="UniformClause"></a>The <tt>uniform</tt> clause</h4><div class="deeper">
The <tt>uniform</tt> clause declares one or more arguments
to have an invariant value for all concurrent invocations
of the function in the execution of a single SIMD loop.
</div><h4><a name="LinearClauseOpenmp 4 5"></a>The <tt>linear</tt> clause (OpenMP 4.5+)</h4><div class="deeper">
The <tt>linear</tt> clause is similar to the <tt>firstprivate</tt>
clause discussed later in this article.
<p>Consider this example code:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> b </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> array</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">];

</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp simd linear(b:2)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> array</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> b</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">%d\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> array</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
What does this code print? If we ignore the SIMD constructs,
we can see it should print the sequence 10,10,10,10,10,10,10,10.
<p>But, if we enable the OpenMP SIMD construct, the program should
now print 10,12,14,16,18,20,22,24. This is because the <tt>linear</tt>
clause tells the compiler, that the value of <tt>b</tt> inside
each iteration of the loop should be a <em>copy</em> of the original
value of <tt>b</tt> before the SIMD construct, plus the loop iteration
number, times the linear scale, which is 2 in this case.
</p><p>In essence, it should be equivalent to the following code:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> b_original </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> b</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> array</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> b_original </span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">*</span><span class="jSfJnSXl1">2</span><span class="jSf9DH-K2">;</span></pre>
However, as of GCC version 6.1.0, the <tt>linear</tt> clause does not
seem to be implemented correctly, at least according to my understanding
of the specification, so I cannot do more experimentation.
</div><h4><a name="InbranchAndNotinbranchClauses"></a>The <tt>inbranch</tt> and <tt>notinbranch</tt> clauses</h4><div class="deeper">
The <tt>inbranch</tt> clause specifies that the function will always
be called from inside a conditional statement of a SIMD loop.
The <tt>notinbranch</tt> clause specifies that the function will never
be called from inside a conditional statement of a SIMD loop.
<p>The compiler may use this knowledge to optimize the code.
</p></div></div><h3><a name="ForSimdConstructOpenmp 4 0"></a>The <tt>for simd</tt> construct (OpenMP 4.0+)</h3><div class="deeper">
The <tt>for</tt> and <tt>simd</tt> constructs can be combined,
to divide the execution of a loop into multiple threads,
and then execute those loop slices in parallel using SIMD.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">float</span><span class="jSf6Z2BR2"> sum</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">float</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> table</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">float</span><span class="jSf6Z2BR2"> result</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp parallel for simd reduction(+:result)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">1000</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> result </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> table</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">n</span><span class="jSf9DH-K2">];
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> result</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
</div><h3><a name="TaskConstructOpenmp 3 0"></a>The <tt>task</tt> construct (OpenMP 3.0+)</h3><div class="deeper">
When <tt>for</tt> and <tt>sections</tt> are too cumbersome, the <tt>task</tt> construct
can be used. This is only supported in OpenMP 3.0 and later.
<p>These examples are from the OpenMP 3.0 manual:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf5gZog2">struct</span><span class="jSf6Z2BR2"> node </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> node </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">left</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">right</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};
</span><span class="jSf5gZog2">extern</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> process</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">node</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> traverse</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">node</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> p</span><span class="jSfoF-_93">)
</span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">if</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">left</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">        </span><span class="jSf-8GPi2">#pragma omp task </span><span class="jSfQHvUD">// p is firstprivate by default
</span><span class="jSf6Z2BR2">        traverse</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">left</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">if</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">right</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">        </span><span class="jSf-8GPi2">#pragma omp task </span><span class="jSfQHvUD">// p is firstprivate by default
</span><span class="jSf6Z2BR2">        traverse</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">right</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    process</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
}</span></pre>
In the next example, we force a postorder traversal of the tree by adding a <tt>taskwait</tt>
directive. Now, we can safely assume that the left and right sons have been executed
before we process the current node.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf5gZog2">struct</span><span class="jSf6Z2BR2"> node </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> node </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">left</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">right</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};
</span><span class="jSf5gZog2">extern</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> process</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">node</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> postorder_traverse</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">node</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> p</span><span class="jSfoF-_93">)
</span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">if</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">left</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">        </span><span class="jSf-8GPi2">#pragma omp task </span><span class="jSfQHvUD">// p is firstprivate by default
</span><span class="jSf6Z2BR2">        postorder_traverse</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">left</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">if</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">right</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">        </span><span class="jSf-8GPi2">#pragma omp task </span><span class="jSfQHvUD">// p is firstprivate by default
</span><span class="jSf6Z2BR2">        postorder_traverse</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">right</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp taskwait
</span><span class="jSf6Z2BR2">    process</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
}</span></pre>
The following example demonstrates how to use the task construct to process elements
of a linked list in parallel. The pointer p is firstprivate by default on the task construct
so it is not necessary to specify it in a firstprivate clause.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf5gZog2">struct</span><span class="jSf6Z2BR2"> node </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> data</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> node</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> next</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};
</span><span class="jSf5gZog2">extern</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> process</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">node</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> increment_list_items</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">node</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> head</span><span class="jSfoF-_93">)
</span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">        </span><span class="jSf-8GPi2">#pragma omp single
</span><span class="jSf6Z2BR2">        </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">            </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">node</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> p </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> head</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> p</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> p </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> p</span><span class="jSfoF-_93">-&gt;</span><span class="jSf6Z2BR2">next</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">            </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">            	</span><span class="jSf-8GPi2">#pragma omp task
</span><span class="jSf6Z2BR2">            	process</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// p is firstprivate by default
</span><span class="jSf6Z2BR2">            </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">        </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}
}</span></pre>
</div></div><h2><a name="OffloadingSupport"></a>Offloading support</h2><div class="deeper">
Offloading means that parts of the program can be executed
not only on the CPU of the computer itself, but also in other
hardware attached to it, such as on the graphics card.
<h3><a name="DeclareTargetAndEndDeclareTargetDirectives"></a>The <tt>declare target</tt> and <tt>end declare target</tt> directives</h3><div class="deeper">
The <tt>declare target</tt> and <tt>end declare target</tt> directives
delimit a section of the source code wherein all declarations,
whether they are variables or functions/subroutines,
are compiled for a device.
<p>Example:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf-8GPi2">#pragma omp declare target
</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> x</span><span class="jSf9DH-K2">;
</span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> murmur</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> x</span><span class="jSfdoBI62">+=</span><span class="jSfJnSXl1">5</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf-8GPi2">#pragma omp end declare target</span></pre>This creates one or more versions of "x" and "murmur".
A set that exists on the host computer, and also a separate
set that exists and can be run on a device.
<p>These two functions and variables are separate,
and may contain values separate from each others.
</p><p>Variables declared in this manner can be accessed by
the device code without separate <tt>map</tt> clauses.
</p><p><b>OpenACC differences</b>
</p><p>In OpenACC, device-functions are declared by prefixing
each function with <tt>#pragma acc routine</tt>.
Its data model is more complicated and
has no direct translation from/to OpenMP.
</p></div><h3><a name="TargetTargetDataConstructs"></a>The <tt>target</tt>, <tt>target data</tt> constructs</h3><div class="deeper">
The <tt>target data</tt> construct creates a device data environment.
<p>The <tt>target</tt> construct executes the construct on a device
(and also has <tt>target data</tt> features).
</p><p>These two constructs are identical in effect:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf-8GPi2">#pragma omp target </span><span class="jSfQHvUD">// device()... map()... if()...
</span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">  </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2">statements</span><span class="jSfoF-_93">...&gt;&gt;
</span><span class="jSf9DH-K2">}</span></pre>
And:
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf-8GPi2">#pragma omp target data </span><span class="jSfQHvUD">// device()... map()... if()...
</span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp target
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2">statements</span><span class="jSfoF-_93">...&gt;&gt;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}
}</span></pre>
<b>IMPORTANT</b>: The <tt>target</tt> construct does not add any parallelism
to the program by itself. It only transfers the execution into another
device, and executes the code there in a single thread.
<p>To utilize parallelism on device, you have to engage a <tt>teams</tt>
construct inside the <tt>target</tt> construct. Example:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">long</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">long</span><span class="jSf6Z2BR2"> r </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">void</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    r</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp target teams distribute parallel for reduction(+:r) map(tofrom:r)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">unsigned</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">long</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">long</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">0x800000000</span><span class="jSfvraDY3">ull</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">        r </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> n</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">r=%llX\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> r</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
See the <tt>teams</tt> keyword below for details.
<h4><a name="IfClause"></a>The <tt>if</tt> clause</h4><div class="deeper">
If an <tt>if</tt> clause is added to the <tt>target</tt> region,
the attached expression is evaluated. If the expression
returns <tt>false</tt>, the code is only executed on the host.
Otherwise, or if the <tt>if</tt> clause is not used,
the code is executed on the device, and the task will wait
until the device is done with the processing.
<p>Example:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdlib.h&gt;
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> argc</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSfoF-_93">**</span><span class="jSf6Z2BR2"> argv</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> r</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp target if(atoi(argv[1])) map(tofrom:r)
</span><span class="jSf6Z2BR2">    r </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">4</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">    printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">r=%d\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> r</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
</div><h4><a name="DeviceClause"></a>The <tt>device</tt> clause</h4><div class="deeper">
Specifices the particular device that is to execute the code.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> device_number </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">...</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#pragma omp target device(device_number)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSfnT6pa2">//...
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
You can acquire device numbers by using the &lt;omp.h&gt; library functions,
such as <tt>omp_set_default_device</tt>, <tt>omp_get_default_device</tt>, <tt>omp_get_num_devices</tt>, and
<tt>omp_is_initial_device</tt>.
<p>If the <tt>device</tt> clause is not used, the code is executed on the default device.
The default device number
is controlled by the <tt>omp_set_default_device</tt> function,
or the <tt>OMP_DEFAULT_DEVICE</tt> environment variable.
</p></div><h4><a name="MapClause"></a>The <tt>map</tt> clause</h4><div class="deeper">
The <tt>map</tt> clause controls how data is between the host and the device.
<p>There are four different types of mappings:
</p><ul><li> <tt>map(alloc:variables)</tt> specifies that at entry to the block, the specified variables have uninitialized values.
</li><li> <tt>map(from:variables)</tt> specifies that at entry to the block, the specified variables have copies of their original values on the host.
</li><li> <tt>map(to:variables)</tt> specifies that at exit from the block, the values of these variables will be copied back to the host.
</li><li> <tt>map(tofrom:variables)</tt> is a combination of <tt>from</tt> and <tt>to</tt>. This is the default mapping.
</li></ul><p>Variables are initialized and assigned through bitwise copy, i.e. constructors / operators are not called.
</p><p>The mapping items can be entire variables or array sections.
</p></div><h4><a name="ArraySectionsOpenmp 4 0"></a>Array sections (OpenMP 4.0+)</h4><div class="deeper">
The variables in <tt>map</tt> and <tt>depend</tt> can also specify array sections.
The array subsections are defined using one of the following syntax:
<ul><li> <tt>[lowerbound:length])</tt>
</li><li> <tt>[lowerbound:])</tt>
</li><li> <tt>[:length])</tt>
</li><li> <tt>[:])</tt>
</li></ul><p>Array sections can only be specified in the <tt>map</tt>, and <tt>depend</tt> clauses.
They are invalid in e.g <tt>private</tt>.
</p><p>An example of a valid array subscript mapping:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> foo </span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> i</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp single
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp target teams distribute parallel for map(p[0:24])
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">i </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> i </span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">24</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> i</span><span class="jSfoF-_93">++)
</span><span class="jSf6Z2BR2">      p</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">i</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> p</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">i</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
</div></div><h3><a name="TargetEnterDataAndTargetExitDataConstructsOpenmp 4 5"></a>The <tt>target enter data</tt> and <tt>target exit data</tt> constructs (OpenMP 4.5+)</h3><div class="deeper">
While the <tt>map</tt> clauses within a <tt>target data</tt> construct can be used to
allocate data in the device memory and automatically deallocate it in the end
of the construct, the <tt>target enter data</tt> and <tt>target exit data</tt> constructs
can be used to store data in the memory in a more persistent manner.
<p>Examples:
</p><ul><li> <tt>#pragma omp target enter data map(from:var)</tt>
</li><li> <tt>#pragma omp target exit  data map(to:var)</tt>
</li></ul></div><h3><a name="TargetUpdateConstruct"></a>The <tt>target update</tt> construct</h3><div class="deeper">
The <tt>target update</tt> construct can be used to synchronize data between
the device memory and the host memory without deallocating it.
<p></p><ul><li> <tt>#pragma omp target  update from(c)</tt>
</li></ul></div></div><h2><a name="Teams"></a>Teams</h2><div class="deeper">
While the <tt>parallel</tt> construct creates a <em>team</em> of <em>threads</em>,
the <tt>teams</tt> construct creates a <em>league</em> of <em>teams</em>.
<p>This directive can be only used directly inside a <tt>target</tt> construct.
The optional attribute <tt>num_teams</tt> can be used to specify the maximum
number of teams created. The actual number of teams may be smaller than this number.
The <em>master</em> thread of each team will execute the code inside that team.
</p><p>The example code below <em>may</em> print the message multiple times.
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">void</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp target teams
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">      printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">test\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
<b>OpenACC differences</b>
<p>OpenACC calls teams and threads <em>gangs</em> and <em>workers</em> respectively.
In OpenACC, a set of new teams is launched on the device
with <tt>#pragma acc parallel</tt>, with the optional attribute <tt>num_gangs(n)</tt>.
This combines the behavior of <tt>#pragma omp target</tt> and <tt>#pragma omp teams</tt>.
</p><h3><a name="DistributeConstruct"></a>The <tt>distribute</tt> construct</h3><div class="deeper">
The <tt>distribute</tt> construct can be used to distribute a <tt>for</tt> loop
across the <em>master</em> threads of all teams of the current <tt>teams</tt> region.
<p>For example, if there are 20 teams,
the loop will be distributed across 20 <em>master</em> threads.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">void</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> r</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp target teams distribute reduction(+:r)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10000</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">      r </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> n</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">    printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">r=%d\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> r</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
<b>OpenACC differences</b>
<p>In OpenACC this behavior is achieved by adding the word <tt>gang</tt>
to existing worksharing constructs like <tt>#pragma acc parallel</tt>
and <tt>#pragma acc kernels</tt>.
</p><h4><a name="DistributeSimdConstruct"></a>The <tt>distribute simd</tt> construct</h4><div class="deeper">
Adding the <tt>simd</tt> clause into the <tt>distribute</tt> construct will
combine the effects of <tt>simd</tt> and <tt>distribute</tt>, meaning that
the loop will be divided across the <em>master</em> threads of all teams
of the current <tt>teams</tt> region, and therein divided according to
the same principles that are in effect in <tt>#pragma omp simd</tt> constructs.
</div><h4><a name="DistScheduleClause"></a>The <tt>dist_schedule</tt> clause</h4><div class="deeper">
Much like with the <tt>schedule</tt> clause used with <tt>for</tt> scheduling,
the scheduling in <tt>distribute</tt> can be controlled with the <tt>dist_schedule</tt> clause.
Currently the only possible value for <tt>dist_schedule</tt> is <tt>static</tt>.
</div></div><h3><a name="DistributeParallelForConstruct"></a>The <tt>distribute parallel for</tt> construct</h3><div class="deeper">
The <tt>distribute parallel for</tt> construct can be used to distribute a <tt>for</tt> loop
across <em>all</em> threads of all teams of the current <tt>teams</tt> region.
<p>For example, if there are 20 teams, and each team consists of 256 threads,
the loop will be distributed across 5120 threads.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">void</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> r</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp target teams distribute parallel for reduction(+:r)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10000</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">      r </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> n</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">    printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">r=%d\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> r</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
The number of threads created in each team is implementation defined,
but can be explicitly defined with the <tt>num_threads</tt> attribute.
<p>The <tt>simd</tt> clause can be added once again to the loop to add SIMD execution, if possible.
</p><p><b>OpenACC differences</b>
</p><p>In OpenACC this behavior is achieved by adding the word <tt>worker</tt>
to existing worksharing constructs like <tt>#pragma acc parallel</tt>
and <tt>#pragma acc kernels</tt>. Additionally the word <tt>vector</tt> can
be added to achieve SIMD parallelism as well.
</p></div></div><h2><a name="ThreadSafetyIEMutualExclusion"></a>Thread-safety (i.e. mutual exclusion)</h2><div class="deeper">
There are a wide array of concurrency and mutual exclusion problems related
to multithreading programs.
I won't explain them here in detail; there are many good books dealing
with the issue.
(For example, <em>Multithreaded, Parallel, and Distributed Programming</em>
by Gregory R. Andrews.)
<p>Instead, I will explain the tools that OpenMP provides
to handle mutual exclusion correctly.
</p><h3><a name="Atomicity"></a>Atomicity</h3><div class="deeper">
Atomicity means that something is inseparable; an event
either happens completely or it does not happen at all,
and another thread cannot intervene during the execution of the event.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp atomic
</span><span class="jSf6Z2BR2"> counter </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> value</span><span class="jSf9DH-K2">;</span></pre>
The <tt>atomic</tt> keyword in OpenMP specifies that the denoted action happens
atomically. It is commonly used to update counters and other simple variables
that are accessed by multiple threads simultaneously.
<p>See also <tt>reduction</tt>.
</p><p>There are four different types of atomic expressions (since OpenMP 3.1):
</p><h4><a name="AtomicReadExpressions"></a>Atomic read expressions</h4><div class="deeper">
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp atomic read
</span><span class="jSf6Z2BR2"> var </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSf9DH-K2">;</span></pre>
Here the reading of <tt>x</tt> is guaranteed to happen atomically, but nothing is guaranteed about <tt>var</tt>.
Note that <tt>var</tt> may not access the memory location designated for <tt>x</tt>.
</div><h4><a name="AtomicWriteExpressions"></a>Atomic write expressions</h4><div class="deeper">
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp atomic write
</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span></pre>
Here the writing of <tt>x</tt> is guaranteed to happen atomically, but nothing is guaranteed about <tt>expr</tt>.
Note that <tt>expr</tt> may not access the memory location designated for <tt>x</tt>.
</div><h4><a name="AtomicUpdateExpressions"></a>Atomic update expressions</h4><div class="deeper">
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp atomic update </span><span class="jSfQHvUD">// The word "update" is optional
</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// One of these:
</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">--</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">++</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">--</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  x </span><span class="jSfdoBI62">-=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  x </span><span class="jSfdoBI62">*=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">   x </span><span class="jSfdoBI62">/=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  x </span><span class="jSfdoBI62">&amp;=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">-</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">-</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">|=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  x </span><span class="jSfdoBI62">^=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  x </span><span class="jSfoF-_93">&lt;&lt;=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  x </span><span class="jSfoF-_93">&gt;&gt;=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">|</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">^</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">&gt;&gt;</span><span class="jSf6Z2BR2">expr</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">|</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">^</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSfoF-_93">&gt;&gt;</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">;</span></pre>
Here the updating of <tt>x</tt> is guaranteed to happen atomically, but nothing is guaranteed about <tt>expr</tt>.
Note that <tt>expr</tt> may not access the memory location designated for <tt>x</tt>.
</div><h4><a name="AtomicCaptureExpressions"></a>Atomic capture expressions</h4><div class="deeper">
Capture expressions combine the <tt>read</tt> and <tt>update</tt> features.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp atomic capture
</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// One of these:
</span><span class="jSf6Z2BR2"> var </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">++</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">  </span><span class="jSfnT6pa2">/* Or any other of the update expressions listed above */
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> var </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">++</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">/* Or any other of of the update expressions listed above */</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">++</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">/* Or any other of of the update expressions listed above */</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> var </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> var </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> x</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> expr</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
Note that neither <tt>var</tt> nor <tt>expr</tt> may not access the memory location designated for <tt>x</tt>.
</div></div><h3><a name="CriticalConstruct"></a>The <tt>critical</tt> construct</h3><div class="deeper">
The <tt>critical</tt> construct restricts the execution of the associated
statement / block to a single thread at time.
<p>The <tt>critical</tt> construct may optionally contain a global name that identifies
the type of the <tt>critical</tt> construct. No two threads can execute a <tt>critical</tt>
construct of the same name at the same time.
</p><p>If the name is omitted, a default name is assumed.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp critical(dataupdate)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   datastructure</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">reorganize</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">...
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp critical(dataupdate)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   datastructure</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">reorganize_again</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>In this example, only one of the critical sections named "dataupdate"
may be executed at any given time, and only one thread may be executing
it at that time. I.e. the functions "reorganize" and "reorganize_again"
cannot be invoked at the same time, and two calls to the function cannot
be active at the same time. (Except if other calls exist elsewhere,
unprotected by the <tt>critical</tt> construct.)
<p>Note: The critical section names are global to the entire program
(regardless of module boundaries). So if you have a critical section
by the same name in multiple modules, not two of them can be executed
at the same time.
</p><p>If you need something like a local mutex, see below.
</p></div><h3><a name="Locks"></a>Locks</h3><div class="deeper">
The OpenMP runtime library provides a lock type, <tt>omp_lock_t</tt>
in its include file, <tt>omp.h</tt>.
<p>The lock type has five manipulator functions:
</p><p></p><ul><li> <tt>omp_init_lock</tt> initializes the lock. After the call, the lock is unset.
</li><li> <tt>omp_destroy_lock</tt> destroys the lock. The lock must be unset before this call.
</li><li> <tt>omp_set_lock</tt> attempts to set the lock. If the lock is already set by another thread, it will wait until the lock is no longer set, and then sets it.
</li><li> <tt>omp_unset_lock</tt> unsets the lock. It should only be called by the same thread that set the lock; the consequences of doing otherwise are undefined.
</li><li> <tt>omp_test_lock</tt> attempts to set the lock. If the lock is already set by another thread, it returns 0; if it managed to set the lock, it returns 1.
</li></ul><p>Here is an example of a wrapper around <tt>std::set&lt;&gt;</tt>
that provides per-instance mutual exclusion while
still working even if the compiler does not support OpenMP.
</p><p>You can maintain backward compability with non-OpenMP-supporting
compilers by enclosing the library references in
<tt>#ifdef _OPENMP</tt>…<tt>#endif</tt> blocks.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#ifdef _OPENMP
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2"># include &lt;omp.h&gt;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#endif
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;set&gt;
</span><span class="jSf6Z2BR2"> 
 </span><span class="jSf5gZog2">class</span><span class="jSf6Z2BR2"> data
 </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">private</span><span class="jSfoF-_93">:
</span><span class="jSf6Z2BR2">   std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">set</span><span class="jSfoF-_93">&lt;</span><span class="jSf5gZog2">int</span><span class="jSfoF-_93">&gt;</span><span class="jSf6Z2BR2"> flags</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#ifdef _OPENMP
</span><span class="jSf6Z2BR2">   omp_lock_t lock</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#endif
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">public</span><span class="jSfoF-_93">:
</span><span class="jSf6Z2BR2">   data</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">:</span><span class="jSf6Z2BR2"> flags</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#ifdef _OPENMP
</span><span class="jSf6Z2BR2">     omp_init_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#endif
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSfoF-_93">~</span><span class="jSf6Z2BR2">data</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#ifdef _OPENMP
</span><span class="jSf6Z2BR2">     omp_destroy_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#endif
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   
   </span><span class="jSf5gZog2">bool</span><span class="jSf6Z2BR2"> set_get</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> c</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#ifdef _OPENMP
</span><span class="jSf6Z2BR2">     omp_set_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#endif
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">bool</span><span class="jSf6Z2BR2"> found </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> flags</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">find</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">c</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">!=</span><span class="jSf6Z2BR2"> flags</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">end</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(!</span><span class="jSf6Z2BR2">found</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> flags</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">insert</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">c</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#ifdef _OPENMP
</span><span class="jSf6Z2BR2">     omp_unset_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#endif
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> found</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};</span></pre>
Of course, you would really rather wrap the lock into
a custom container to avoid littering the code with <tt>#ifdef</tt>s
and also for providing exception-safety:
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#ifdef _OPENMP
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2"># include &lt;omp.h&gt;
</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">struct</span><span class="jSf6Z2BR2"> MutexType
 </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   MutexType</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> omp_init_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSfoF-_93">~</span><span class="jSf6Z2BR2">MutexType</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> omp_destroy_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> Lock</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> omp_set_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> Unlock</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> omp_unset_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   
   MutexType</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> MutexType</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> omp_init_lock</span><span class="jSfoF-_93">(&amp;</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   MutexType</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">operator</span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> MutexType</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2">this</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">public</span><span class="jSfoF-_93">:
</span><span class="jSf6Z2BR2">   omp_lock_t lock</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#else
</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">/* A dummy mutex that doesn't actually exclude anything,
  * but as there is no parallelism either, no worries. */
</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">struct</span><span class="jSf6Z2BR2"> MutexType
 </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> Lock</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{}
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> Unlock</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#endif
</span><span class="jSf6Z2BR2"> 
 </span><span class="jSfnT6pa2">/* An exception-safe scoped lock-keeper. */
</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">struct</span><span class="jSf6Z2BR2"> ScopedLock
 </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">explicit</span><span class="jSf6Z2BR2"> ScopedLock</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">MutexType</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2"> m</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">:</span><span class="jSf6Z2BR2"> mut</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">m</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> locked</span><span class="jSfoF-_93">(</span><span class="jSfWtbTI">true</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> mut</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">Lock</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSfoF-_93">~</span><span class="jSf6Z2BR2">ScopedLock</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> Unlock</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> Unlock</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(!</span><span class="jSf6Z2BR2">locked</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">return</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> locked</span><span class="jSfdoBI62">=</span><span class="jSfWtbTI">false</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> mut</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">Unlock</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> LockAgain</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">locked</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">return</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> mut</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">Lock</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> locked</span><span class="jSfdoBI62">=</span><span class="jSfWtbTI">true</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">private</span><span class="jSfoF-_93">:
</span><span class="jSf6Z2BR2">   MutexType</span><span class="jSfoF-_93">&amp;</span><span class="jSf6Z2BR2"> mut</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">bool</span><span class="jSf6Z2BR2"> locked</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">private</span><span class="jSfoF-_93">:</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// prevent copying the scoped lock.
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">operator</span><span class="jSfdoBI62">=</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> ScopedLock</span><span class="jSfoF-_93">&amp;)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   ScopedLock</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> ScopedLock</span><span class="jSfoF-_93">&amp;)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};</span></pre>
This way, the example above becomes a lot simpler, and also exception-safe:
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;set&gt;
</span><span class="jSf6Z2BR2"> 
 </span><span class="jSf5gZog2">class</span><span class="jSf6Z2BR2"> data
 </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">private</span><span class="jSfoF-_93">:
</span><span class="jSf6Z2BR2">   std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">set</span><span class="jSfoF-_93">&lt;</span><span class="jSf5gZog2">int</span><span class="jSfoF-_93">&gt;</span><span class="jSf6Z2BR2"> flags</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   MutexType lock</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">public</span><span class="jSfoF-_93">:
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">bool</span><span class="jSf6Z2BR2"> set_get</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> c</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     ScopedLock lck</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">lock</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// locks the mutex
</span><span class="jSf6Z2BR2">     
     </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">flags</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">find</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">c</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">!=</span><span class="jSf6Z2BR2"> flags</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">end</span><span class="jSfoF-_93">())</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">true</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// was found
</span><span class="jSf6Z2BR2">     flags</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">insert</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">c</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">false</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// was not found
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// automatically releases the lock when lck goes out of scope.
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};</span></pre>
There is also a lock type that supports nesting, <tt>omp_nest_lock_t</tt>.
I will not cover it here.
</div><h3><a name="FlushDirective"></a>The <tt>flush</tt> directive</h3><div class="deeper">
Even when variables used by threads are supposed to be shared,
the compiler may take liberties and optimize them as register
variables. This can skew concurrent observations of the variable.
The <tt>flush</tt> directive can be used to ensure that the value
observed in one thread is also the value observed by other
threads.
<p>This example comes from the OpenMP specification.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">          </span><span class="jSfnT6pa2">/* presumption: int a = 0, b = 0; */
</span><span class="jSf6Z2BR2">                        
    </span><span class="jSfnT6pa2">/* First thread */</span><span class="jSf6Z2BR2">                </span><span class="jSfnT6pa2">/* Second thread */
</span><span class="jSf6Z2BR2">    b </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">                            a </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp flush(a,b)            #pragma omp flush(a,b)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">a </span><span class="jSfoF-_93">==</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2">                        </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">b </span><span class="jSfoF-_93">==</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2">                                 </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">      </span><span class="jSfnT6pa2">/* Critical section */</span><span class="jSf6Z2BR2">            </span><span class="jSfnT6pa2">/* Critical section */
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}</span><span class="jSf6Z2BR2">                                 </span><span class="jSf9DH-K2">}</span></pre>
In this example, it is enforced that at the time either of <tt>a</tt>
or <tt>b</tt> is accessed, the other is also up-to-date, practically
ensuring that not both of the two threads enter the critical section.
(Note: It is still possible that neither of them can enter it.)
<p>You need the <tt>flush</tt> directive when you have writes to and reads from
the same data in different threads.
</p><p><b>If the program appears to work correctly without the <tt>flush</tt> directive,
it does not mean that the <tt>flush</tt> directive is not required.</b>
It just may be that your compiler is not utilizing all the freedoms the
standard allows it to do. You <em>need</em> the <tt>flush</tt> directive whenever
you access shared data in multiple threads: After a write, before a read.
</p><p>However, I do not know these:
</p><ul><li> Is <tt>flush</tt> needed if the shared variable is declared <tt>volatile</tt>?
</li><li> Is <tt>flush</tt> needed if all access to the shared variable is <tt>atomic</tt> or restricted by <tt>critical</tt> sections?
</li></ul></div></div><h2><a name="ControllingWhichDataToShareBetweenThreads"></a>Controlling which data to share between threads</h2><div class="deeper">
In the parallel section, it is possible to specify which variables
are shared between the different threads and which are not.
By default, all variables are shared except those declared within
the parallel block.
<h3><a name="PrivateFirstprivateAndSharedClauses"></a>The <tt>private</tt>, <tt>firstprivate</tt> and <tt>shared</tt> clauses</h3><div class="deeper">
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> b</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel for private(a) shared(b)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">a</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> a</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">50</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">a</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp atomic
</span><span class="jSf6Z2BR2">   b </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
This example explicitly specifies that <tt>a</tt> is private
(each thread has their own copy of it) and that <tt>b</tt>
is shared (each thread accesses the same variable).
<h4><a name="DifferenceBetweenPrivateAndFirstprivate"></a>The difference between <tt>private</tt> and <tt>firstprivate</tt></h4><div class="deeper">
Note that a private copy is an uninitialized variable by the same name
and same type as the original variable; it does <em>not</em> copy the value
of the variable that was in the surrounding context.
<p>Example:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;string&gt;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;iostream&gt;
</span><span class="jSf6Z2BR2"> 
 </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">string a </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">x</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> b </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">y</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> c </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">3</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     
     </span><span class="jSf-8GPi2">#pragma omp parallel private(a,c) shared(b) num_threads(2)
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">         a </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">k</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         c </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">7</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">cout </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">A becomes (</span><span class="jSfMt2g81">"</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> a </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">), b is (</span><span class="jSfMt2g81">"</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> b </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">)\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
This will output the string "k", not "xk".
At the entrance of the block, <tt>a</tt> becomes a new instance
of <tt>std::string</tt>, that is initialized with the default
constructor; it is not initialized with the copy constructor.
<p>Internally, the program becomes like this:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">string a </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">x</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> b </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">y</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> c </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">3</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     
     OpenMP_thread_fork</span><span class="jSfoF-_93">(</span><span class="jSfJnSXl1">2</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2">                  </span><span class="jSfnT6pa2">// Start new scope
</span><span class="jSf6Z2BR2">         std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">string a</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// Note: It is a new local variable.
</span><span class="jSf6Z2BR2">         </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> c</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">         </span><span class="jSfnT6pa2">// This too.
</span><span class="jSf6Z2BR2">         a </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">k</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         c </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">7</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">cout </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">A becomes (</span><span class="jSfMt2g81">"</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> a </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">), b is (</span><span class="jSfMt2g81">"</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> b </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">)\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">}</span><span class="jSf6Z2BR2">                  </span><span class="jSfnT6pa2">// End of scope for the local variables
</span><span class="jSf6Z2BR2">     OpenMP_join</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
In the case of primitive (POD) datatypes (<tt>int</tt>, <tt>float</tt>, <tt>char*</tt> etc.),
the private variable is uninitialized, just like any declared
but not initialized local variable. It does not contain the
value of the variable from the surrounding context.
Therefore, the increment of <tt>c</tt> is moot here; the value of
the variable is still undefined. (If you are using GCC version
earlier than 4.4, you do not even get a warning about the use
of uninitialized value in situations like this.)
<p>If you actually need a <em>copy</em> of the
original value, use the <tt>firstprivate</tt> clause instead.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;string&gt;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;iostream&gt;
</span><span class="jSf6Z2BR2"> 
 </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">string a </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">x</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> b </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">y</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> c </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">3</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     
     </span><span class="jSf-8GPi2">#pragma omp parallel firstprivate(a,c) shared(b) num_threads(2)
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">         a </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">k</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         c </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">7</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">         std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">cout </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">A becomes (</span><span class="jSfMt2g81">"</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> a </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">), b is (</span><span class="jSfMt2g81">"</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> b </span><span class="jSfoF-_93">&lt;&lt;</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">)\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
Now the output becomes "A becomes (xk), b is (y)".
</div></div><h3><a name="LastprivateClause"></a>The <tt>lastprivate</tt> clause</h3><div class="deeper">
The <tt>lastprivate</tt> clause defines a variable private
as in <tt>firstprivate</tt> or <tt>private</tt>, but causes the
value from the last task to be copied back to the original
value after the end of the loop/sections construct.
<p></p><ul><li> In a loop construct (<tt>for</tt> construct), the last value is the value assigned by the thread that handles the last iteration of the loop. Values assigned during other iterations are ignored.
</li><li> In a sections construct (<tt>sections</tt> construct), the last value is the value assigned in the last section denoted by the <tt>section</tt> construct. Values assigned in other sections are ignored.
</li></ul><p>Example:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;
</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> done </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">4</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> done2 </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">5</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    
     </span><span class="jSf-8GPi2">#pragma omp parallel for lastprivate(done, done2) num_threads(2) schedule(static)
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> a</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> a</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">8</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">a</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">       </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">a</span><span class="jSfoF-_93">==</span><span class="jSfJnSXl1">2</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> done</span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2">done2</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">       </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">a</span><span class="jSfoF-_93">==</span><span class="jSfJnSXl1">3</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> done</span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2">done2</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">     printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">%d,%d\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> done</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">done2</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>This program outputs "4196224,-348582208", because internally, this program
became like this:
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;
</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> done </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">4</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> done2 </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">5</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    OpenMP_thread_fork</span><span class="jSfoF-_93">(</span><span class="jSfJnSXl1">2</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">        </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> this_thread </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> omp_get_thread_num</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> num_threads </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">2</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">        </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> my_start </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">this_thread  </span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">8</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> num_threads</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">        </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> my_end   </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">this_thread</span><span class="jSfoF-_93">+</span><span class="jSfJnSXl1">1</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">8</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">/</span><span class="jSf6Z2BR2"> num_threads</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2">        </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> priv_done</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> priv_done2</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// not initialized, because firstprivate was not used

</span><span class="jSf6Z2BR2">        </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> a</span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2">my_start</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> a</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">my_end</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">a</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">        </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">            </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">a</span><span class="jSfoF-_93">==</span><span class="jSfJnSXl1">2</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> priv_done</span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2">priv_done2</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">            </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">a</span><span class="jSfoF-_93">==</span><span class="jSfJnSXl1">3</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> priv_done</span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2">priv_done2</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">        </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">        </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">my_end </span><span class="jSfoF-_93">==</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">8</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">        </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">           </span><span class="jSfnT6pa2">// assign the values back, because this was the last iteration
</span><span class="jSf6Z2BR2">           done  </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> priv_done</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">           done2 </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> priv_done2</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">        </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    OpenMP_join</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>As one can observe, the values of priv_done and priv_done2 are
not assigned even once during the course of the loop that
iterates through 4...7. As such, the values that are assigned
back are completely bogus.
<p>Therefore, <tt>lastprivate</tt> cannot be used to e.g. fetch
the value of a flag assigned randomly during a loop.
Use <tt>reduction</tt> for that, instead.
</p><p>Where this behavior <em>can</em> be utilized though, is in
situations like this (from OpenMP manual):
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> loop</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> i</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp for lastprivate(i)
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">i</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> i</span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2">get_loop_count</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">i</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// note: get_loop_count() must be a pure function.
</span><span class="jSf6Z2BR2">       </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">...</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   
   printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">%d\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> i</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// this shows the number of loop iterations done.
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
</div><h3><a name="DefaultClause"></a>The <tt>default</tt> clause</h3><div class="deeper">
The most useful purpose on the <tt>default</tt> clause is to
check whether you have remembered to consider all variables
for the private/shared question, using the <tt>default(none)</tt>
setting.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> b</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// This code won't compile: It requires explicitly
</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// specifying whether a is shared or private.
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel default(none) shared(b)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   b </span><span class="jSfdoBI62">+=</span><span class="jSf6Z2BR2"> a</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
The <tt>default</tt> clause can also be used to set that all
variables are <tt>shared</tt> by default (<tt>default(shared)</tt>).
<p></p><blockquote>  Note: Because different compilers have different ideas about which
  variables are <em>implicitly</em> private or shared, and for which it is
  an <em>error</em> to explicitly state the private/shared status, it is
  recommended to use the <tt>default(none)</tt> setting only during
  development, and drop it in production/distribution code.
</blockquote></div><h3><a name="TheReductionClause_2"></a>The <tt>reduction</tt> clause</h3><div class="deeper">
The <tt>reduction</tt> clause is a mix between the <tt>private</tt>, <tt>shared</tt>,
and <tt>atomic</tt> clauses.<br>
It allows to accumulate a shared variable without the <tt>atomic</tt> clause,
but the type of accumulation must be specified. It will often produce
faster executing code than by using the <tt>atomic</tt> clause.
<p>This example calculates <a class="extlink" id="iFB1BB060" href="http://en.wikipedia.org/wiki/factorial">factorial</a>
using threads:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> factorial</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> number</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> fac </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp parallel for reduction(*:fac)
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">2</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;=</span><span class="jSf6Z2BR2">number</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">     fac </span><span class="jSfdoBI62">*=</span><span class="jSf6Z2BR2"> n</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> fac</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
<ul><li> At the beginning of the parallel block, a private copy is made of the variable and preinitialized to a certain value .
</li><li> At the end of the parallel block, the private copy is atomically merged into the shared variable using the defined operator.
</li></ul>(The private copy is actually just a new local variable by
the same name and type; the original variable is not accessed
to create the copy.)
<p>The syntax of the clause is:
</p><pre>  reduction(<em>operator</em>:<em>list</em>)
</pre>where <em>list</em> is the list of variables where the operator
will be applied to, and <em>operator</em> is one of these:
<table class="wikitable" border="1"><tbody><tr><th>  Operator</th><th>  Initialization value</th></tr>
<tr><td>  <tt>+</tt>, <tt>-</tt>, <tt>|</tt>, <tt>^</tt>, <tt>||</tt></td><td>  <tt>0</tt></td></tr>
<tr><td>  <tt>*</tt>, <tt>&amp;&amp;</tt></td><td>  <tt>1</tt></td></tr>
<tr><td>  <tt>&amp;</tt></td><td>  <tt>~0</tt></td></tr>
<tr><td>  <tt>min</tt></td><td>  largest representable number</td></tr>
<tr><td>  <tt>max</tt></td><td>  smallest representable number</td></tr>
</tbody></table><p>To write the factorial function (shown above)
without <tt>reduction</tt>, it probably would look like this:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> factorial</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> number</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> fac </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp parallel for
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">2</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;=</span><span class="jSf6Z2BR2">number</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     </span><span class="jSf-8GPi2">#pragma omp atomic
</span><span class="jSf6Z2BR2">     fac </span><span class="jSfdoBI62">*=</span><span class="jSf6Z2BR2"> n</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> fac</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>However, this code would be less optimal than the one with <tt>reduction</tt>:
it misses the opportunity to use a local (possible register) variable
for the cumulation, and needlessly places load/synchronization demands
on the shared memory variable. In fact, due to the bottleneck of that
atomic variable (only one thread may access it simultaneously),
it would completely nullify any gains of parallelism in that loop.
<p>The version with <tt>reduction</tt> is equivalent to this code (illustration only):
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> factorial</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> number</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> fac </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> omp_priv </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">/* This value comes from the table shown above */
</span><span class="jSf6Z2BR2">     </span><span class="jSf-8GPi2">#pragma omp for nowait
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">2</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;=</span><span class="jSf6Z2BR2">number</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">       omp_priv </span><span class="jSfdoBI62">*=</span><span class="jSf6Z2BR2"> n</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf-8GPi2">#pragma omp atomic
</span><span class="jSf6Z2BR2">     fac </span><span class="jSfdoBI62">*=</span><span class="jSf6Z2BR2"> omp_priv</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> fac</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>Note how it moves the atomic operation out from the loop.
<p>The restrictions in <tt>reduction</tt> and <tt>atomic</tt> are very similar:
both can only be done on POD types; neither allows overloaded
operators, and both have the same set of supported operators.
</p><p>As an example of how the <tt>reduction</tt> clause can be used to produce
semantically different code when OpenMP is enabled and when it
is disabled, this example prints the number of threads that
executed the parallel block:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> a </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel reduction (+:a)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   a </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// Assigns a value to the private copy.
</span><span class="jSf6Z2BR2">   </span><span class="jSfnT6pa2">// Each thread increments the value by 1.
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">%d\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> a</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span></pre>If you preinitialized "a" to 4, it would print a number &gt;= 5
if OpenMP was enabled, and 1 if OpenMP was disabled.<br>
<em>Note: If you really need to detect whether OpenMP is enabled,
use the <tt>_OPENMP</tt> #define instead. To get the number of threads,
use <tt>omp_get_num_threads()</tt> instead.</em>
<h4><a name="DeclareReductionDirectiveOpenmp 4 0"></a>The <tt>declare reduction</tt> directive (OpenMP 4.0+)</h4><div class="deeper">
The <tt>declare reduction</tt> directive generalizes the reductions
to include user-defined reductions.
<p>The syntax of the declaration is one of these two:
</p><p><tt>#pragma omp declare reduction(name:type:expression)</tt><br>
<tt>#pragma omp declare reduction(name:type:expression) initializer(expression)</tt><br>
</p><p></p><ul><li> The <em>name</em> is the name you want to give to the reduction method.
</li><li> The <em>type</em> is the type of your reduction result.
</li><li> Within the <tt>reduction</tt> expression, the special variables <tt>omp_in</tt> and <tt>omp_out</tt> are implicitly declared, and they stand for the input and output expressions respectively.
</li><li> Within the <tt>initializer</tt> expression, the special variable <tt>omp_priv</tt> is implicitly declared and stands for the initial value of the reduction result.
</li></ul><p>An example use case is when you are running a data compressor
with different parameters, and you want to find the set of parameters
that results in best compression. Below is an example of such code:
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;cstdio&gt;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> compress</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> param1</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> param2</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">param1</span><span class="jSfoF-_93">+</span><span class="jSfJnSXl1">13</span><span class="jSfoF-_93">)^</span><span class="jSf6Z2BR2">param2</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// Placeholder for a compression algorithm
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> argc</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSfoF-_93">**</span><span class="jSf6Z2BR2"> argv</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">struct</span><span class="jSf6Z2BR2"> BestInfo </span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">unsigned</span><span class="jSf6Z2BR2"> size</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> param1</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> param2</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">};

</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp declare reduction(isbetter:BestInfo: \
                                  omp_in.size&lt;omp_out.size ? omp_out=omp_in : omp_out \   
                    ) initializer(omp_priv = BestInfo{~0u,~0u,~0u})  

</span><span class="jSf6Z2BR2">    BestInfo result</span><span class="jSf9DH-K2">{</span><span class="jSfoF-_93">~</span><span class="jSfJnSXl1">0</span><span class="jSfvraDY3">u</span><span class="jSf9DH-K2">,</span><span class="jSfoF-_93">~</span><span class="jSfJnSXl1">0</span><span class="jSfvraDY3">u</span><span class="jSf9DH-K2">,</span><span class="jSfoF-_93">~</span><span class="jSfJnSXl1">0</span><span class="jSfvraDY3">u</span><span class="jSf9DH-K2">};
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp parallel for collapse(2) reduction(isbetter:result)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">unsigned</span><span class="jSf6Z2BR2"> p1</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> p1</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">p1</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">unsigned</span><span class="jSf6Z2BR2"> p2</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> p2</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">p2</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">      </span><span class="jSf5gZog2">unsigned</span><span class="jSf6Z2BR2"> size </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> compress</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">p1</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">p2</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">      </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">size </span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2"> result</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">size</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> result </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> BestInfo</span><span class="jSf9DH-K2">{</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">p1</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">p2</span><span class="jSf9DH-K2">};
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    std</span><span class="jSfJiEpd3">::</span><span class="jSf6Z2BR2">printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">Best compression (%u bytes) with params %u,%u\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,
</span><span class="jSf6Z2BR2">      result</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> result</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">param1</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> result</span><span class="jSfoF-_93">.</span><span class="jSf6Z2BR2">param2</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
</div></div></div><h2><a name="ThreadAffinityProcBind"></a>Thread affinity (<tt>proc_bind</tt>)</h2><div class="deeper">
The thread affinity of the <tt>parallel</tt> construct can be controlled
with a <tt>proc_bind</tt> clause. It takes one of the following three forms:
<p></p><ul><li> <tt>#pragma omp parallel proc_bind(master)</tt>
</li><li> <tt>#pragma omp parallel proc_bind(close)</tt>
</li><li> <tt>#pragma omp parallel proc_bind(spread)</tt>
</li></ul><p>For more information, read the OpenMP specification.
</p></div><h2><a name="ExecutionSynchronization"></a>Execution synchronization</h2><div class="deeper">
<h3><a name="BarrierDirectiveAndTheNowaitClause"></a>The <tt>barrier</tt> directive and the <tt>nowait</tt> clause</h3><div class="deeper">
The <tt>barrier</tt> directive causes threads encountering the barrier
to wait until all the other threads in the same team
have encountered the barrier.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSfnT6pa2">/* All threads execute this. */
</span><span class="jSf6Z2BR2">   SomeCode</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   
   </span><span class="jSf-8GPi2">#pragma omp barrier
</span><span class="jSf6Z2BR2">   
   </span><span class="jSfnT6pa2">/* All threads execute this, but not before
    * all threads have finished executing SomeCode().
    */
</span><span class="jSf6Z2BR2">   SomeMoreCode</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
Note: There is an implicit barrier at the end of each parallel
block, and at the end of each <tt>sections</tt>, <tt>for</tt> and <tt>single</tt>
statement, unless the <tt>nowait</tt> directive is used.
<p>Example:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp for
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> Work</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   
   </span><span class="jSfnT6pa2">// This line is not reached before the for-loop is completely finished
</span><span class="jSf6Z2BR2">   SomeMoreCode</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}

</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// This line is reached only after all threads from
</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// the previous parallel block are finished.
</span><span class="jSf6Z2BR2"> CodeContinues</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;

</span><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp for nowait
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> n</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> n</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">10</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">n</span><span class="jSfoF-_93">)</span><span class="jSf6Z2BR2"> Work</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   
   </span><span class="jSfnT6pa2">// This line may be reached while some threads are still executing the for-loop.
</span><span class="jSf6Z2BR2">   SomeMoreCode</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}

</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// This line is reached only after all threads from
</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// the previous parallel block are finished.
</span><span class="jSf6Z2BR2"> CodeContinues</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span></pre>
The <tt>nowait</tt> directive can only be attached to <tt>sections</tt>, <tt>for</tt> and <tt>single</tt>.
It cannot be attached to the within-loop <tt>ordered</tt> clause, for example.
</div><h3><a name="SingleAndMasterConstructs"></a>The <tt>single</tt> and <tt>master</tt> constructs</h3><div class="deeper">
The <tt>single</tt> construct specifies that the given statement/block
is executed by only one thread. It is unspecified which thread.
Other threads skip the statement/block and wait at an implicit
barrier at the end of the construct.
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   Work1</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp single
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     Work2</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   Work3</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>In a 2-cpu system, this will run Work1() twice, Work2() once
and Work3() twice. There is an implied barrier at the end of
the <tt>single</tt> construct, but not at the beginning of it.
<p>Note: Do not assume that the <tt>single</tt> block is executed by whichever
thread gets there first. According to the standard, the decision of
which thread executes the block is implementation-defined, and
therefore making assumptions on it is non-conforming.
</p><p>The <tt>master</tt> construct is similar, except that the statement/block
is run by the <em>master</em> thread, and there is no implied barrier;
other threads skip the construct without waiting.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   Work1</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   
   </span><span class="jSfnT6pa2">// This...
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp master
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     Work2</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   
   </span><span class="jSfnT6pa2">// ...is practically identical to this:
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">omp_get_thread_num</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">==</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     Work2</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   
   Work3</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
Unless you use the <tt>threadprivate</tt> clause, the only important
difference between <tt>single nowait</tt> and <tt>master</tt> is that if
you have multiple <tt>master</tt> blocks in a <tt>parallel</tt> section,
you are guaranteed that they are executed by the same thread
every time, and hence, the values of <tt>private</tt> (thread-local)
variables are the same.
</div></div><h2><a name="ThreadCancellationOpenmp 4 0"></a>Thread cancellation (OpenMP 4.0+)</h2><div class="deeper">
Suppose that we want to optimize this function with parallel
processing:
<pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">/* Returns any position from the haystack where the needle can
  * be found, or NULL if no such position exists. It is not guaranteed
  * to find the first matching position; it only guarantees to find
  * _a_ matching position if one exists.
  */
</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> FindAnyNeedle</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> haystack</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> size_t size</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSf6Z2BR2"> needle</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">size_t p </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> p </span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2"> size</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">     </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">haystack</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">p</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">==</span><span class="jSf6Z2BR2"> needle</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">       </span><span class="jSfnT6pa2">/* This breaks out of the loop. */
</span><span class="jSf6Z2BR2">       </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> haystack</span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2">p</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">     </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> NULL</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>
Our first attempt might be to simply tack a <tt>#pragma parallel for</tt>
before the <tt>for</tt> loop, but that doesn't work: OpenMP requires that
a loop construct processes each iteration. Breaking out of the loop
(using <tt>return</tt>, <tt>goto</tt>, <tt>break</tt>, <tt>throw</tt>
or other means) is not allowed.
<p>To solve this problem, OpenMP 4.0 added a mechanism called <tt>cancellation points</tt>,
and a <tt>cancel</tt> construct. Cancellation points are implicitly inserted at the following
positions:
</p><ul><li> Implicit barriers
</li><li> <tt>barrier</tt> regions
</li><li> <tt>cancel</tt> regions
</li><li> <tt>cancellation point</tt> regions
</li></ul><p>It can be used to solve finder problems where N threads search
for a solution and once a solution is found by any thread,
all threads end their search.
</p><p>Because there is a performance overhead in checking for cancellations, it is only
enabled if the library-internal global variable OMP_CANCELLATION is set.
The value of this variable can be checked with the <tt>omp_get_cancellation()</tt> function,
but there is no way modify it from inside the program.
It can only be set from the environment when the program is launched.
</p><p>In this example program, once a thread finds the "needle", it signals
cancellation for all threads of the current team processing the innermost <tt>for</tt> loop.
Threads check the cancellation only at every loop iteration.
It also checks whether OMP_CANCELLATION is set, and if not, sets it and reruns the program.
</p><p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;  </span><span class="jSfQHvUD">// For printf
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;string.h&gt; </span><span class="jSfQHvUD">// For strlen
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdlib.h&gt; </span><span class="jSfQHvUD">// For putenv
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;unistd.h&gt; </span><span class="jSfQHvUD">// For execv
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;omp.h&gt;    </span><span class="jSfQHvUD">// For omp_get_cancellation, omp_get_thread_num()

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">static</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> FindAnyNeedle</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> haystack</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> size_t size</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSf6Z2BR2"> needle</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf5gZog2">const</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSfoF-_93">*</span><span class="jSf6Z2BR2"> result </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> haystack</span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2">size</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp parallel
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">      </span><span class="jSf5gZog2">unsigned</span><span class="jSf6Z2BR2"> num_iterations</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">      </span><span class="jSf-8GPi2">#pragma omp for
</span><span class="jSf6Z2BR2">      </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">size_t p </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> p </span><span class="jSfoF-_93">&lt;</span><span class="jSf6Z2BR2"> size</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">      </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">        </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">num_iterations</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">        </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">haystack</span><span class="jSf9DH-K2">[</span><span class="jSf6Z2BR2">p</span><span class="jSf9DH-K2">]</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">==</span><span class="jSf6Z2BR2"> needle</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">        </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">          </span><span class="jSf-8GPi2">#pragma omp atomic write
</span><span class="jSf6Z2BR2">          result </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> haystack</span><span class="jSfoF-_93">+</span><span class="jSf6Z2BR2">p</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">          </span><span class="jSfnT6pa2">// Signal cancellation.
</span><span class="jSf6Z2BR2">          </span><span class="jSf-8GPi2">#pragma omp cancel for
</span><span class="jSf6Z2BR2">        </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">        </span><span class="jSfnT6pa2">// Check for cancellations signalled by other threads:
</span><span class="jSf6Z2BR2">        </span><span class="jSf-8GPi2">#pragma omp cancellation point for
</span><span class="jSf6Z2BR2">      </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">      </span><span class="jSfnT6pa2">// All threads reach here eventually; sooner if the cancellation was signalled.
</span><span class="jSf6Z2BR2">      printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">Thread %u: %u iterations completed\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> omp_get_thread_num</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> num_iterations</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> result</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> argc</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSf5gZog2">char</span><span class="jSfoF-_93">**</span><span class="jSf6Z2BR2"> argv</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(!</span><span class="jSf6Z2BR2">omp_get_cancellation</span><span class="jSfoF-_93">())
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">      printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">Cancellations were not enabled, enabling cancellation and rerunning program\n</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">      putenv</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">OMP_CANCELLATION=true</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">      execv</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">argv</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">],</span><span class="jSf6Z2BR2"> argv</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    printf</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">%s\n%*s\n</span><span class="jSfMt2g81">"</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> argv</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">],</span><span class="jSf6Z2BR2"> FindAnyNeedle</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">argv</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">],</span><span class="jSf6Z2BR2">strlen</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">argv</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">]</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">argv</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">2</span><span class="jSf9DH-K2">][</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">]</span><span class="jSfoF-_93">)-</span><span class="jSf6Z2BR2">argv</span><span class="jSf9DH-K2">[</span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">]</span><span class="jSfoF-_93">+</span><span class="jSfJnSXl1">1</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2"> </span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">^</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>
Example output:
<p></p><pre>   ./a.out "OpenMP cancellations can only be performed synchronously at cancellation points." "l"
   Cancellations were not enabled, enabling cancellation and rerunning program
   Thread 0: 10 iterations completed
   Thread 1: 3 iterations completed
   Thread 7: 10 iterations completed
   Thread 3: 10 iterations completed
   Thread 4: 10 iterations completed
   Thread 2: 8 iterations completed
   Thread 5: 5 iterations completed
   Thread 6: 6 iterations completed
   OpenMP cancellations can only be performed synchronously at cancellation points.
                              ^
</pre>The keyword in the end of the <tt>#pragma omp cancellation point</tt> construct is
the name of the most closely nested OpenMP construct that you want to cancel.
In the example code above, it is the <tt>for</tt> construct, and this is why
the line says <tt>#pragma omp cancellation point for</tt>.
<p>OpenMP cancellations can only be performed synchronously at cancellation points.
GNU pthreads also permits asynchronous cancellations. This is rarely used, and
requires special setup, because there are several resource leak risks involved in it.
An example of such code can be found here:
<a class="extlink" id="i5F5840D2" href="http://bisqwit.iki.fi/jutut/kuvat/openmphowto/pthread_cancel_demo.cpp">http://bisqwit.iki.fi/jutut/kuvat/openmphowto/pthread_cancel_demo.cpp</a>
</p></div><h2><a name="LoopNesting"></a>Loop nesting</h2><div class="deeper">
<h3><a name="Problem"></a>The problem</h3><div class="deeper">
A beginner at OpenMP will quickly find out that this code will
not do the expected thing:
<p></p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel for
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> y</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> y</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">25</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">y</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp parallel for
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> x</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">80</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">x</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     tick</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">y</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>The beginner expects there to be N tick() calls active at the same
time (where N = number of processors). Although that is true, the
inner loop is not actually parallelised. Only the outer loop is.
The inner loop runs in a pure sequence, as if the whole
inner <tt>#pragma</tt> was omitted.
<p>At the entrance of the inner <tt>parallel</tt> construct, the OpenMP runtime library
(libgomp in case of GCC) detects that there already exists a team, and instead
of a new team of N threads, it will create a team consisting of only the
calling thread.
</p><p>Rewriting the code like this won't work:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel for
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> y</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> y</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">25</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">y</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   </span><span class="jSf-8GPi2">#pragma omp for </span><span class="jSfQHvUD">// ERROR, nesting like this is not allowed.
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> x</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">80</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">x</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     tick</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">y</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">}</span></pre>This code is erroneous and will cause the program to malfunction.
See the restrictions chapter below for details.
<h4><a name="SolutionInOpenmp 3 0"></a>Solution in OpenMP 3.0</h4><div class="deeper">
In OpenMP 3.0, the loop nesting problem can be solved by using
the <tt>collapse</tt> clause in the <tt>for</tt> construct.
<p>Example:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2"> </span><span class="jSf-8GPi2">#pragma omp parallel for collapse(2)
</span><span class="jSf6Z2BR2"> </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> y</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> y</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">25</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">y</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">for</span><span class="jSfoF-_93">(</span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> x</span><span class="jSfdoBI62">=</span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> x</span><span class="jSfoF-_93">&lt;</span><span class="jSfJnSXl1">80</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfoF-_93">++</span><span class="jSf6Z2BR2">x</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     tick</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">x</span><span class="jSf9DH-K2">,</span><span class="jSf6Z2BR2">y</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}</span></pre>
The number specified in the <tt>collapse</tt> clauses is the number
of nested loops that are subject to the work-sharing semantics
of the OpenMP <tt>for</tt> construct.
</div></div><h3><a name="Restrictions"></a>Restrictions</h3><div class="deeper">
There are restrictions to which clauses can be nested under which constructs.
The restrictions are listed in the OpenMP official specification.
</div></div><h2><a name="Performance"></a>Performance</h2><div class="deeper">
Compared to a naive use of C++11 threads, OpenMP threads are often
more efficient. This is because many implementations of OpenMP use
a <em>thread pool</em>.
A thread pool means that new operating system threads are only created once.
When the threads are done with their work,
they return to a “dock” waiting for new work to do.
</div><h2><a name="Shortcomings"></a>Shortcomings</h2><div class="deeper">
<h3><a name="OpenmpAndFork"></a>OpenMP and fork()</h3><div class="deeper">
It is worth mentioning that using OpenMP in a program
that calls <tt>fork()</tt> requires special consideration.
<p>This problem only affects GCC; ICC is not affected.
</p><p>If your program intends to become a background process
using <tt>daemonize()</tt> or other similar means, you must not
use the OpenMP features <em>before</em> the fork. After OpenMP
features are utilized, a fork is only allowed if the child
process does not use OpenMP features, or it does so as
a completely new process (such as after <tt>exec()</tt>).
</p><p>This is an example of an erroneous program:
</p><pre class="source_snippet" style="background-color:#FFF;color:#000"><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;stdio.h&gt;
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;sys/wait.h&gt;
</span><span class="jSf6Z2BR2">  </span><span class="jSf-8GPi2">#include &lt;unistd.h&gt;

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> a</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp parallel num_threads(2)
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">      puts</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">para_a</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// output twice
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    puts</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">a ended</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// output once
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">void</span><span class="jSf6Z2BR2"> b</span><span class="jSfoF-_93">()
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">    </span><span class="jSf-8GPi2">#pragma omp parallel num_threads(2)
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">      puts</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">para_b</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">    </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">    puts</span><span class="jSfoF-_93">(</span><span class="jSfMt2g81">"</span><span class="jSf1vtiR2">b ended</span><span class="jSfMt2g81">"</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}

</span><span class="jSf6Z2BR2">  </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> main</span><span class="jSfoF-_93">()</span><span class="jSf6Z2BR2"> </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">   a</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2">   </span><span class="jSfnT6pa2">// Invokes OpenMP features (parent process)
</span><span class="jSf6Z2BR2">   </span><span class="jSf5gZog2">int</span><span class="jSf6Z2BR2"> p </span><span class="jSfdoBI62">=</span><span class="jSf6Z2BR2"> fork</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">if</span><span class="jSfoF-_93">(!</span><span class="jSf6Z2BR2">p</span><span class="jSfoF-_93">)
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">{
</span><span class="jSf6Z2BR2">     b</span><span class="jSfoF-_93">()</span><span class="jSf9DH-K2">;</span><span class="jSf6Z2BR2"> </span><span class="jSfnT6pa2">// ERROR: Uses OpenMP again, but in child process
</span><span class="jSf6Z2BR2">     _exit</span><span class="jSfoF-_93">(</span><span class="jSfJnSXl1">0</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSf9DH-K2">}
</span><span class="jSf6Z2BR2">   wait</span><span class="jSfoF-_93">(</span><span class="jSf6Z2BR2">NULL</span><span class="jSfoF-_93">)</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">   </span><span class="jSfWtbTI">return</span><span class="jSf6Z2BR2"> </span><span class="jSfJnSXl1">0</span><span class="jSf9DH-K2">;
</span><span class="jSf6Z2BR2">  </span><span class="jSf9DH-K2">}</span></pre>When run, this program hangs, never reaching
the line that outputs "b ended".
<p>There is currently no workaround; the libgomp API does not specify
functions that can be used to prepare for a call to <tt>fork()</tt>.
</p></div></div><h2><a name="MissingInThisArticle"></a>Missing in this article</h2><div class="deeper">
<ul><li> The <tt>depend</tt> clause (added in OpenMP 4.0)
</li><li> The <tt>nowait</tt> clause in <tt>target</tt> construct (added in OpenMP 4.5)
</li><li> The <tt>taskgroup</tt> construct (added in OpenMP 4.0)
</li><li> The <tt>taskyield</tt> construct (added in OpenMP 3.1)
</li><li> The <tt>final</tt>, <tt>mergeable</tt>, and <tt>priority</tt> clauses in <tt>task</tt> (added in OpenMP 3.1 through 4.5)
</li><li> The <tt>threadprivate</tt>, <tt>copyprivate</tt> and <tt>copyin</tt> clauses
</li><li> The <tt>ref</tt>, <tt>val</tt>, and <tt>uval</tt> modifiers in <tt>linear</tt> clause (added in OpenMP 4.5)
</li><li> The <tt>hint</tt> clause in <tt>critical</tt> construct (added in OpenMP 4.5)
</li><li> The <tt>defaultmap</tt> clause (added in OpenMP 4.5)
</li></ul></div><h2><a name="SomeSpecificGotchas"></a>Some specific gotchas</h2><div class="deeper">
<b>C++</b>
<p></p><ul><li> STL is not thread-safe. If you use STL containers in a parallel context, you <em>must</em> exclude concurrent access using locks or other mechanisms. Const-access is usually fine, as long as non-const access does not occur at the same time.
</li><li> Exceptions may not be thrown and caught across omp constructs. That is, if a code inside an <tt>omp for</tt> throws an exception, the exception must be caught before the end of the loop iteration; and an exception thrown inside a <tt>parallel</tt> section must be caught by the same thread before the end of the <tt>parallel</tt> section.
</li></ul><p><b>GCC</b>
</p><p></p><ul><li> <tt>fork()</tt> is troublematic when used together with OpenMP. See the chapter "OpenMP and fork()" above for details.
</li></ul><p></p><hr>
</div><h2><a name="FurtherReading"></a>Further reading</h2><div class="deeper">
<div class="diggbutton" style="float:right;margin-left:20px"><a href="http://www.reddit.com/submit?url=http%3A%2F%2Fbisqwit.iki.fi%2Fstory%2Fhowto%2Fopenmp%2F&amp;title=Guide+into+OpenMP%3A+Easy+multithreading+programming+for+C%2B%2B">Submit to Reddit</a></div> <div class="diggbutton" style="float:right;margin-left:20px"><a href="http://digg.com/submit?phase=2&amp;url=http%3A%2F%2Fbisqwit.iki.fi%2Fstory%2Fhowto%2Fopenmp%2F&amp;title=Guide+into+OpenMP%3A+Easy+multithreading+programming+for+C%2B%2B">Submit to Digg</a></div>
The official specification of OpenMP is the document that dictates
what a conforming compiler should do. If you have any question
regarding OpenMP, the official specification answers the questions.
If it is not there, it is undefined.
<p></p><ul><li> <a class="extlink" id="i9B7CCAF8" href="http://www.openmp.org/mp-documents/openmp-4.5.pdf">The OpenMP 4.5 official specification</a>
</li><li> <a class="extlink" id="iCD72F87C" href="http://en.wikipedia.org/wiki/OpenMP">Wikipedia article for OpenMP</a>
</li><li> <a class="extlink" id="i235EBCF2" href="http://people.arsc.edu/~cskills/lectures/OmpCrash.pdf">OpenMP crash course at ARSC — has especially good list of gotchas.</a>
</li><li> <small><a class="extlink" id="iE4A2B52A" href="http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf">The OpenMP 4.0 official specification</a></small>
</li><li> <small><a class="extlink" id="i624444F1" href="http://www.openmp.org/mp-documents/spec30.pdf">The OpenMP 3.0 official specification</a></small>
</li><li> <small><a class="extlink" id="i515CA54E" href="http://www.openmp.org/mp-documents/spec25.pdf">The OpenMP 2.5 official specification</a></small>
</li><li> <a class="broken" href="https://enwikipediaorg/wiki/XeonPhi.html">Wikipedia article for Xeon Phi — for more information about Intel MIC</a>
</li></ul></div></div><hr>
<div class="lastedit">
Last edited at: 2016-06-15T17:36:47+03:00</div>
 

</body></html>